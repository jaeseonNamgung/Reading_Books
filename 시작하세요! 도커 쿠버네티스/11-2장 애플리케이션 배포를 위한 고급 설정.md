# 쿠버네티스 스케줄링

스케줄링이란 컨테이너나 가상머신 같은 인스턴스를 새롭게 생성할 때, 그 인스턴스를 어느 서버에 생성할 것일지 결정하는 일을 뜻한다.

## 파드가 실제로 노드에 생성되기까지의 과정

1. `ServiceAccount`, `RoleBinding` 등의 기능을 이용해 파드 생성을 요청한 사용자의 인증 및 인가 작업을 수행한다.
2. `ResourceQuata`, `LimitRange`와 같은 어드미션 컨트롤러가 해당 파드 요청을 적절히 변형(Mutate) 하거나 검증(Validate)한다.
3. 어드미션 컨트롤러의 검증을 통과해 최종적으로 파드 생성이 승인됐다면 해당 파드를 워커 노드 중 한 곳에 생성한다.

> 핵심 컴포넌트들은 `kube-system` 네임스페이스에서 실행되고 있다.
>

스케줄링에 관여하는 컴포넌트는 `kube-scheduler` 와 `etcd` 이다.  `kube-scheduler` 는 쿠버네티스 스케줄러에 해당하며,  `etcd` 는 쿠버네티스 클러스터의 전반적인 상태 데이터를 저장하는 일종의 데이터베이스 역할을 담당한다.

> `etcd` 는 분산 코디네이터(Distibuted Coordinator)라고 불리는 도구의 일종으로, 클라우드 플랫폼 등의 환경에서 여러 컴포넌트가 정상적으로 상호작용할 수 있도록 데이터를 조정하는 역할을 담당한다. 쿠버네티스 또한 클러스터 운용에 필요한 정보를 분산 코디네이터인 `etcd` 에 저장하는데, 디플로이먼트나 파드의 목록과 정보, 클러스터 자체의 정보 등과 같은 대부분의 데이터가 `etcd` 에 저장돼 있다.
>
- `etcd` 에 저장된 데이터는 무조건 API 서버(kube-apiserver)를 통해서만 접근할 수 있다.
- `etcd` 에 저장된 파드의 데이터에는 해당 파드가 어느 워커 노드에서 실행되는지를 나타내는  `nodeName` 항목이 존재한다.

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: nginx
spec:
  nodeName: ip-10-43-0-30.ap-northeast-2.compute.internal
  containers:
  - name: nginx
    image: nginx:latest
```

인증, 인가, 어드미션 컨트롤러 등의 단계를 모두 커쳐 파드 생성 요청이 최종적으로 승인됐다면 API 서버는 `etcd`에 파드의 데이터를 저장한다. 하지만 API 서버는 파드의 데이터 중에서 **nodeName 항목을 설정하지 않은 상태**로 etcd에 저장한다. 아직은 스케줄링이 수행되지 않았기 때문에 파드가 실제로 생성되지 않은, 단순히 데이터로만 저장된 상태이기 때문이다.

쿠버네티스 스케줄러 컴포넌트에 해당하는 `kube-scheduler` 는 API 서버의 `Watch` 를 통해 `nodeName` 이 비어 있는 파드 데이터가 저장됐다는 사실을 전달 받는다. 즉, 사용자의 파드 생성 요청에 의해 파드의 데이터가 `etcd` 에 저장되긴 했지만, 아직 특정 노드의 스케줄링되지 않은 파드를 감지하는 것이다. 스케줄러(kube-scheduler)는 `nodeName` 이 설정되지 않은 해당 파드를 스케줄링 대상으로 판단하고, 파드를 할당할 적절한 노드를 선택한 다음 API 서버에게 해당 노드와 파드를 바인딩할 것을 요청한다. 그러고 나면 **파드의 `nodeName` 항목의 값에는 선택된 노드의 이름이 설정된다.**

클러스터의 각 노드에서 실행 중인 `kubelet` 은 API 서버에 걸어 둔 `Watch` 를 통해 파드의 데이터에서  `nodeName` 이 설정됐다는 소식을 전달 받는다. 그러고 나서야 비로서 해당 `nodeName` 에 해당하는 노드의 `kubelet` 이 컨테이너 런타임을 통해 파드를 생성한다.

# 파드가 생성될 노드를 선택하는 스케줄링 과정

- 노드 필터링:  파드를 할당할 수 있는 노드와 그렇지 않은 노드를 분리해 걸러내는(Filtering) 단계
- 노드 스코어링: 쿠버네티스의 소스코드에 미리 정의된 알고리즘의 가중치에 따라서 노드의 점수를 계산
    - 노드 스코어링은 쿠버네티스에 내장된 로직에 의해 계산되기 때문에 알고리즘을 수정하는 경우는 많지 않다.

# NodeSelector와 Node Affinity, Pod Affinity

## nodeName과 nodeSelector를 이용한 스케줄링 방법

[nodeName 방법]

- 특정 워커 노드에 파드를 할당하는 가장 확실한 방법은 파드의 YAML 파일에 노드의 이름(nodeName)을 직접 명시하는 것이다. (권장 되지 않음)

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: nginx
spec:
  nodeName: ip-10-43-0-30.ap-northeast-2.compute.internal
  containers:
  - name: nginx
    image: nginx:latest
```

노드의 이름을 고정으로 설정하면 다른 환경에서 이 YAML 파일을 보편적으로 사용하기 어렵다. 또한 노드에 장애가 발생했을 때 유연하게 대처하기가 어렵다.

[nodeSelector 방법]

nodeName 대신 사용할 수 있는 방법중 노드의 라벨(Label)을 사용하는 것이 있다. 라벨을 이용하면 특정 라벨이 존재하는 노드에만 파드를 할당할 수 있다.

> 노드의 라벨은 쿠버네티스가 자동으로 설정해 놓은 것도 있지만 직접 라벨을 추가할 수 있다. 미리 설정된 라벨은 대부분 `kubernetes.io/` 라는 접두어로 시작한다.
>

```bash
kubectl get nodes --show-labels # 노드의 라벨 확인

# 노드 라벨 추가 방법
kubectl label nodes <노드 이름> <추가할 라벨 ex mylabel/disk=ssd> 

#노드 라벨 삭제 방법 `-(대시)`추가
kubectl label nodes <노드 이름> mylabel/disk=ssd-
```

```yaml
# nodeSelector 사용 예시 
apiVersion: v1
kind: Pod
metadata:
  name: nginx-nodeselector
spec:
  nodeSelector:
    mylabel/disk: hdd
  containers:
  - name: nginx
    image: nginx:latest
```

- mylabel/disk: hdd라는 라벨을 갖는 노드가 2개 이상이라면 해당 노드 중 하나가 선택된다.
    - `nodeSelector` 는 단일 파드에 대해 수행된다.
        - 여러 개의 파드를 생성하도록 설정된 디플로이먼트의 파드들은 한꺼번에 동일하게 스케줄링되는 것이 아닌, 각 파드가 하나씩 독립적으로 스케줄링된다.

## Node Affinity를 이용한 스케줄링 방법

`Nodd Affinity`는 `nodeSelector` 에서 좀 더 확장된 라벨 선택 기능을 제공하며, 반드시 충족해야 하는 **조건(Hard)**과 선호하는 **조건(Soft)**을 별도로 정의할 수 있다.

- requiredDuringSchedulingIgnoredDuringExecution (Hard)
- preferredDuringSchedulingIgnoredDuringExecution (Soft)

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: nginx-nodeaffinity-required
spec:
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchExpressions:
          - key: mylabel/disk         
            operator: In          # values의 값 중 하나만 만족하면 됩니다.
            values:
            - ssd
            - hdd 
  containers:
  - name: nginx
    image: nginx:latest
```

- `requiredDuringSchedulingIgnoredDuringExecution` : 무조건 존재해야 한다는 뜻
- `operator: In` : key의 라벨이 values의 값 중 하나를 만족하는 노드에 파드를 스케줄링
    - Operator 종류:  `In`, `NotIn` , `Exists` , `DoesNotExist` , `Gt` (값이 큼), `Lt` (값이 작음)

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: nginx-pod-antiaffinity-preferred
spec:
  affinity:
    podAntiAffinity:
      preferredDuringSchedulingIgnoredDuringExecution:
      - podAffinityTerm:
          labelSelector:
            matchExpressions:
            - key: mylabel/database
              operator: In
              values:
              - mysql
          topologyKey: failure-domain.beta.kubernetes.io/zone
        weight: 80
  containers:
  - name: nginx
    image: nginx:latest
```

- `preferredDuringSchedulingIgnoredDuringExecution` 옵션은 무조건 존재할 필요는 없으며, 만약 해당 조건을 만족하는 노드가 있다면 그 노드를 좀 더 선호하겠다는 뜻
- `weight`: 조건에 해당하는 노드를 얼마나 선호할지를 나타내는 가중치
    - 즉 때에 따라서 `matchExpressions` 의 조건을 만족하는 노드를 반드시 선택하지 않을 수도 있지만, 가급적이면 해당 노드를 선택하도록 가산점을 부여
    - **1~100**까지의 값을 사용할 수 있다. (노드 스코어링 단계에서 적용됨)

> 이러한 스케줄링 조건은 파드를 할당할 당시에만 유효하다. 따라서 일단 파드가 할당된 뒤에 노드의 라벨이 변경되더라도 다른 노드로 파드가 옮겨가는 퇴거(Eviction) 가 발생하지 않는다.
스케줄링 과정에서는 유효하지만(required During Scheduling),  일단 실행이 된 다음에는 무시된다(Ignored During Execution)
>

# Pod Affinity를 이용한 스케줄링 방법

`Pod Affinity` 는 특정 조건을 만족하는 파드와 함께 실행되도록 스케줄링한다.

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: nginx-podaffinity
spec:
  affinity:
    podAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
      - labelSelector:
          matchExpressions:
          - key: mylabel/database 
            operator: In
            values:
            - mysql
        topologyKey: failure-domain.beta.kubernetes.io/zone
  containers:
  - name: nginx
    image: nginx:latest
```

- `mylabel/data=mysql` 이라는 라벨을 가지는 파드와 함께 위치하도록 스케줄링하라는 뜻
- `topologyKey` : 해당 라벨을 가지는 토폴로지 범위의 노드를 선택한다는 것을 의미
  - 노드 라벨을 이용해 pod의 affinity와 antiaffinity를 설정할 수 있는 또 하나의 기준이다.
  - 쿠버네티스는 pod를 스케줄링할 때 먼저 pod의 label을 기준으로 대상 노드를 찾고, 이후 topologyKey 필드를 확인해 해당 노드가 원하는 노드인지 확인한다.
> 조건을 만족하는 노드에 할당될 수도 있지만 해당 노드와 동일한 그룹(topology)에 속하는 다른 노드에 파드가 할당될 수도 있다.
예시:  응답 시간을 최대한 줄여야 하는 두 개의 파드를 동일한 가용 영역(AZ: Avaliable Zone) 또는 리전(Region) 의 노드에 할당하는 경우
>

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: nginx-podaffinity-hostname
spec:
  affinity:
    podAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
      - labelSelector:
          matchExpressions:
          - key: mylabel/database
            operator: In
            values:
            - mysql
        topologyKey: kubernetes.io/hostname
  containers:
  - name: nginx
    image: nginx:latest
```

- `Kubernetes.io/hostname` 라벨은 쿠버네티스를 설치하면 기본적으로 모든 노드에 설정되는 라벨이다.
- **기본적으로 모든 노드의 호스트 이름은 고유하기 때문에 하나의 토폴로지에  두 개 이상의 노드가 존재할 수 없다.**

# Pod Anti-Affinity를 이용한 스케줄링 방법

- `Pod Anti-affinity` 는 특정 파드와 같은 토폴로지의 노드를 선택하지 않도록 스케줄링한다.
- `Pod Anti-affinity` 를 잘 이용하면 고가용성을 보장하기 위해 파드를 여러 가용 영역 또는 리전에 멀리 퍼뜨리는 전략을 세울 수 있다.

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: nginx-podaffinity
spec:
  affinity:
    podAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
      - labelSelector:
          matchExpressions:
          - key: mylabel/database
            operator: In
            values:
            - mysql
        topologyKey: failure-domain.beta.kubernetes.io/zone
  containers:
  - name: nginx
    image: nginx:latest
```

- `Pod Anti-affinity` 를 사용하면 `matchExpression` 조건을 만족하는 파드가 위치한 노드와 다른 토폴리지의 노드에 파드가 할당된다.

> `requiredDuringSchedulingIgnoredDuringExecution` 을 사용하면 토폴리지마다 반드시 하나의 파드만 할당하게 되지만, `preferredDuringSchedulingIgnoredDuringExecution` 을 사용하면 각 토폴리지의 노드에 파드를 여러 개 할당할 수 있다.  (모든 노드에 파드를 하나씩 할당하는 데몬셋(DaemonSet)과 비슷한 디플로이먼트를 생성할 수도 있다.)
>

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: nginx-pod-antiaffinity-preferred
spec:
  affinity:
    podAntiAffinity:
      preferredDuringSchedulingIgnoredDuringExecution:
      - podAffinityTerm:
          labelSelector:
            matchExpressions:
            - key: mylabel/database
              operator: In
              values:
              - mysql
          topologyKey: failure-domain.beta.kubernetes.io/zone
        weight: 80
  containers:
  - name: nginx
    image: nginx:latest
```

# Taints와 Tolerations 사용하기

## Taints와 Tolerations를 이용한 파드 스케줄링

- `Taints`: 특정 노드에 얼룩(Taint)을 지정함으로써 해당 노드에 파드가 할당되는 것을 막는 기능
- `Tolerations` : `Taints` 가 설정된 노드에도 파드를 할당할 수 있게 하는 기능

`Taints` 는 노드에 별도로 설정할 수도 있고, 특정 이벤트로 인해 쿠버네티스가 자동으로 노드에 `Taints` 를 설정하기도 한다.

`kubectl` 명령어로 직접 노드에 설정하거나 해제할 수 있다.

```bash
# Taints 추가
kubectl taint nodes nodename key=value:effect

# Taints 해제
# 노드의 Taints를 삭제할 때는 라벨과 마찬가지로 -(대시)를 뒤에 붙이면 된다.
kubectl taint nodes nodename key:effect-
```

- 라벨과 다른점: `key=value` 뒤에 `effect(Taint 효과)` 를 추가로 명시
- Taints 효과: `Taints` 가 노드에 설정됐을 때 어떠한 효과를 낼 것인지를 결정
- Taints 효과에는 `NoSchedule(파드를 스케줄링하지 않음)` , `NoExecute(파드의 실행 자체를 허용하지 않음)` , `PreferNoSchedule(가능하면 스케줄링하지 않음)` 총 3가지가 있다.

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: nginx-toleration-test
spec:
  tolerations:
  - key: alicek106/my-taint 
    value: dirty              
    operator: Equal          # alicek106/my-taint 키의 값이 dirty이며 (Equal)
    effect: NoSchedule       # Taint 효과가 NoSchedule인 경우 해당 Taint를 용인합니다.
  containers:
  - name: nginx
    image: nginx:latest
```

- Taint를 용인할 수 있을 뿐, 해당 Taint가 설정된 노드에 반드시 파드를 할당한다는 의미는 아님

> 마스터 노드에 기본적으로 파드를 생성할 때 마스터 노드에 할당되는 것을 방지하도록 Taint가 설정되어 있다.
>

> Taint는 기본적으로 키-값의 형태를 가지지만, 값을 생략할 수도 있다. 값이 생략된 경우 `""(빈 문자열)` 의 값을 가지는 것으로 간주한다.
>

[마스터 노드를 스케주링 대상으로 설정하는 법 - 파드의 YAML 파일에 마스터 노드의 Toleration을 정의]

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: nginx-master-toleration
spec:
  tolerations:
  - key: node-role.kubernetes.io/master  
    effect: NoSchedule                  
    operator: Equal
    value: ""
  nodeSelector:
    node-role.kubernetes.io/master: ""   # 마스터 노드에서도 포드가 생성되도록 지정합니다.
  containers:
  - name: nginx
    image: nginx:latest
```

> Toleration에서  operation의 값은 `Equal` 외에도 `Exists` 를 사용할 수 있다.
`Exists` 로 설정된 경우에는 Taint에 대한 와일드카드로서 동작한다.
>

### NoExecute와 tolerationSeconds

- NoExecute: 파드를 해당 노드에 스케줄링하지 않을 뿐만 아니라 해당 노드에서 아예 파드를 실행할 수 없도록 설정
    - NoSchedule는 노드에 설정하더라도 기존에 실행 중이던 파드는 정상적으로 동작
    - NoExecute는 해당 노드에서 실행중인 파드를 종료

> 단, 파드가 디플로이먼트나 레플리카셋 등과 같은 리소스로부터 생성됐다면 NoExecute에 의해 파드가 종료됐더라도 파드는 다른 노드로 옮겨가는, 이른바 **퇴거(Eviction)**가 발생한다.
>
- 파드를 생성하면 쿠버네티스는 자동으로 `NoExecute` 에 대한 Toleration을 추가한다.

```yaml
kubectl describe pod <PodName> 
......
Toleration:  node.kubernetes.io/not-ready:NoExecute for 300s
						 node.kubernetes.io/unreachable.NoExecute for 300s
```

- 노드가 준비되지 않았거나 네트워크 통신이 불가능한 상황일 때를 위한 Toleration이다.
    - `NotReady`: 노드가 준비되지 않은 상태
    - `Unreachable`: 네트워크가 불안정한 상태
    - `memory-pressure`: 메모리 부족
    - `disk-pressure`: 디스크 공간 부족
- `300s` : 300초 동안은 해당 Taint를 용인
    - 300초 이내에 노드가 정상 상태로 돌아와 Taint가 삭제되지 않으면 파드는 다른 노드로 옮겨간다.
    - 즉, 노드가 장애가 생겨도 해당 노드에서 실행 중이던 파드가 즉시 다른 노드로 옮겨 가는 것은 아니다. (기본적으로 300초 후에 옮겨가게 된다.)

# Cordon, Drain 및 PodDiscributionBudget

## cordon을 이용한 스케줄링 비활성화

- `kubectl cordon` 명령어를 사용하면 해당 노드에 더 이상 파드가 스케줄링 되지 않는다.

```bash
kubectl cordon <NodeName>

# cordon을 해제하려면 uncordon 명령어 사용
kubectl uncordon <NodeName>
```

- `cordon` 명령어로 지정된 노드는 새로운 파드가 할당되지 않는다.
    - 노드 상태가 `SchedulingDisabled` 로 되어 있음
- 노드에 `cordon` 명령어를 사용하더라도 해당 노드에서 이미 실행 중인 파드가 종료되지 않는다.
    - `cordon` 명령어는 NoExecute가 아닌 NoSchedule 효과가 있는 Taint를 노드에 추가하기 때문이다.

## drain 명령어로 노드 비활성화하기

- `drain` 은 `cordon` 처럼 해당 노드에 스케줄링을 금지한다는 것은 같지만, 노드에서 기존에 실행 중이던 파드를 다른 노드로 옮겨가도록 **퇴거(Eviction)를 수행한다.**
- `drain` 명령어를 사용하면 해당 노드에는 파드가 실행되지 않기 때문에 커널 버전 업그레이드, 유지 보수 등의 이유로 인해 잠시 노드를 중지해야 할 때 유용하게 사용할 수 있는 명령어이다.

```bash
kubectl drain <NodeName>

# 데몬셋을 무시하고 노드를 drain 
kubectl drain <NodeName> --ignore-daemonset

# 디플로이먼트나 레플리카셋, 잡, 스테이트풀셋 등에 의해 생성되지 않은 파드 (단일 파드)
kubectl drain <NodeName> --force
```

## PodDisruptionBudget으로 파드 개수 유지하기

- `PodDisruptionBudget` 은 `kubectl drain` 명령어 등으로 인해 파드가 퇴거(Eviction)가 발생할 때, 특정 개수 또는 비율만큼의 파드는 반드시 정상적인 상태를 유지하기 위해서 사용된다.
- `PodDisruptionBudget` 는 쿠버네티스 오브젝트이다.

```bash
kubectl get poddisruptionbudgets
# 혹은
kubectl get pdb 
```

```yaml
apiVersion: policy/v1beta1
kind: PodDisruptionBudget
metadata:
  name: simple-pdb-example
spec:
maxUnavailable: 1        # 비활성화될 수 있는 포드의 최대 갯수 또는 비율 (%) 
  # minAvailable: 2
  selector:                 # PDB의 대상이 될 포드를 선택하는 라벨 셀렉터 
    matchLabels:
      app: webserver
```

- maxUnavaliable: `kubectl drain` 등에 의해 노드의 파드가 종료될 때, 최대 몇 개 까지 동시에 종료될 수 있는지를 뜻한다.
- minAvaliable: 파드의 퇴거가 발생할 때, 최소 몇 개의 파드가 정상 상태를 유지해야 하는지를 의미한다.

> maxUnavaliable과 minAvaliable은 의미만 다를 뿐 맥락상으로는 같은 기능이므로 PodDisruptionBudget에는 둘 중 하나만을 정의해야 한다.
>
- selector에서는 PodDisruptionBudget이 적용될 파드의 라벨을 입력한다.
    - **디플로이먼트와 같은 컨트롤러의 라벨이 아닌 파드의 라벨을 입력해야 한다.**

## 커스텀 스케줄러

- 쿠버네티스는 `kube-system` 네임스페이스에 존재하는 기본 스케줄러(kube-scheduler) 외에도 여러 개의 스케줄러를 동시에 사용할 수 있도록 지원한다. → 직접 구현 필요
- 파드를 생성할 때 `schedulerName` 항목을 정의하지 않으면 쿠버네티스는 기본적으로 `default-scheduler라는 값을 설정하는데, 이는 기본 스케줄러를 의미한다.
- 직접 커스텀한 스케줄러로 파드를 스케줄링하고 싶다면 파드를 생성 할 때 `schedulerName` 의 값을 별도로 명시하면 된다.

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: custom-scheduled-pod
spec:
  schedulerName: my-custom-scheduler
  containers:
  - name: nginx-container
    image: nginx
```
