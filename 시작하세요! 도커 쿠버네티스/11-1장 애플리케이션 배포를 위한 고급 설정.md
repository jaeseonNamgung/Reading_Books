# 파드의 자원 사용량 제한

쿠버네티스와 같은 컨테이너 오케스트레이션 툴의 가장 큰 장점 중 하나는 여러 대의 서버를 묶어 리소스 풀로 사용할 수 있다는 것이다. 클러스터의 CPU나 메모리 등의 자원이 부족할 때, 필요한 용량만큼의 서버를 동적으로 추가함으로써 수평적으로 확장할 수 있다.

스케일 아웃(Scale-out)만큼 중요한 작업인 **컴퓨팅 자원 활용률(Utilization)**이 있다.

자원 활용률은 서버 클러스터에서 자원을 얼마나 효율적으로, 빠짐없이 사용하고 있는지를 의미한다.

# 컨테이너와 파드의 자원 사용량 제한

쿠버네티스에서 자원 할당량을 설정하지 않으면 파드의 컨테이너가 노드의 물리 자원을 모두 사용할 수 있기 때문에 노드의 자원이 모두 고갈되는 상황이 발생할 수도 있다.

- 이를 예방할 수 있는 가장 간단한 방법은 파드 자체에 자원 사용량을 명시적으로 설정하는 것이다.

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: resource-limit-pod
  labels:
    name: resource-limit-pod
spec:
  containers:
  - name: nginx
    image: nginx:latest
    resources:
      limits:
        memory: "256Mi"
        cpu: "1000m"
```

- CPU에는 1개의 CPU를 뜻하는 1000m(밀리코어)라는 값을 입력했으며, 이는 도커 명령어에서 `docker-run --cpus 1`과 같다

# 컨테이너와 파드의 자원 제한량 제한하기 : Requests

- `Limits` 는 해당 파드의 컨테이너가 최대로 사용할 수 있는 자원의 상한선을 의미한다.
- `Requests` 는 *적어도 이 만큼의 **자원은 컨테이너에 보장돼야 한다는 것을 의미한다.***
    - `requests`는 컨테이너가 보장받아야 하는 최소한의 자원을 뜻하기 때문에 노드의 총 자원의 크기보다 더 많은 양의 `requests` 를 할당할 수 없다.
- `오버커밋(Overcommit)` 은 한정된 컴퓨팅 자원을 효율적으로 사용하기 위한 방법으로, 사용할 수 있는 자원보다 더 많은 양을 가상 머신이나 컨테이너에 할당함으로써 전체 자원의 사용률(Utilization)을 높이는 방법이다.

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: resource-limit-with-request-pod
  labels:
    name: resource-limit-with-request-pod
spec:
  containers:
  - name: nginx
    image: nginx:latest
    resources:
      limits:
        memory: "256Mi"
        cpu: "1000m"
      requests:
        memory: "128Mi"
        cpu: "500m"
```

# CPU 자원 사용량의 제한 원리

- CPU의 Requests는 docker run의 `--cpu-shares` 옵션과 같다.
- `--cpu-shares` 는 서버에 CPU가 실제로 몇 개가 있는지에 상관없이 `--cpu-shares` 의 할당 비율에 따라서 컨테이너가 사용할 수 있는 CPU 자원이 결정되는 옵션이다.
- `--cpu-shares` 가 설정된 여러 개의 컨테이너가 동시에 존재한다면 각 컨테이너의 `--cpu-shares` 비율에 따라 CPU를 사용할 수 있다.
- CPU 스로틀(throttle)이 발생

# QoS 클래스와 메모리 자원 사용량 제한 원리

- 파드의 컨테이너는 최대 Limits 만큼의 자원을 사용할 수 있지만, 최소한 Requests 만큼의 자원을 사용할 수 있도록 보장을 받는다.
- 프로세스의 메모리는 이미 데이터가 메모리에 적재돼 있기 때문에 CPU와 달리 메모리의 압축 불가능한(Incompressible) 자원으로 취급된다.
- 따라서 하나의 노드에서 여러 개의 컨테이너가 Requests 보다 더 많은 자원을 사용하려고 시도해도  이미 메모리에 적재된 데이터를 압축할 수는 없다.
- 이러한 상황에서 쿠버네티스는 가용 메모리를 확보하기 위해 **우선순위가 낮은 파드 또는 프로세스를 강제로 종료하도록 설계돼 있다.**
    - 강제로 종료된 파드는 다른 노드로 옮겨가게 되는데, 쿠버네티스는 이를 **퇴거(Eviction)** 라고 표현한다.

# 쿠버네티스에서의 메모리 부족과 OOM(Out Of Memory)

- 쿠버네티스의 노드에는 각종 노드의 이상 상태 정보를 의미하는 **Conditions** 라는 값이 존재한다.
- 이상 상태의 종류에는 `MemoryPressure` , `DiskPressure` 등이 있다.
- 쿠버네티스 에이전트인 `kubelet` 은 노드의 자원 상태를 주기적으로 확인하면서 Conditions의 `MemoryPressure` , `DiskPressure` 등의 값을 갱신한다.
- 평소에 메모리가 부족하지 않을 때는 `MemoryPressure` 의 값이  `False`로 설정돼 있다.
- 만약 노드의 가용 메모리가 부족해지면 `MemoryPressure` 의 값이 `True` 로 바뀐다.
- `MemoryPressure` 는  기본적으로 노드의 가용 메모리가 `100Mi` 이하일 때 발생하도록 `kubelet` 에 설정돼 있다.
- `MemoryPressure` 가 발생하면 쿠버네티스는 해당 노드에서 실행 중이던 모든 파드에 대해 순위를 매긴 다음, 가장 우선 순위가 낮은 파드를 다른 노드로 퇴거(Evict) 시킨다.
- `MemoryPressure` 값이 `True` 인 노드에는 더 이상 파드를 할당하지 않는다.
- `Kubelet` 이 `MemoryPressure` 상태를 감지하기 전에 급작스럽게 메모리 사용량이 많아질 경우, 리눅스 시스템의 OOM(Out of Memory) Killer라는 기능이 우선순위 점수가 가장 낮은 컨테이너의 프로세스를 강제로 종료해 사용 가능한 메모리를 확보할 수도 있다.

[OOM 우선 순위]

- `oom_score-adj`
- `oom_score`  (OOM Killer는 `oom_score` 의 값에 따라서 종료할 프로세스를 선정)

OOM Killer는 리눅스에 기본적으로 내장된 기능이기 때문에 아무것도 설정하지 않아도 모든 프로세스에 OOM 점수가 매겨진다. OOM 점수는 높으면 높을수록 강제로 종료될 가능성이 커진다. (핵심 프로세스는 일반적으로 낮은 값을 부여받음)

- `kubelet` 은 기본적으로 OOM 점수가 `-999` 로 설정되어 있다. (종료될 일이 거의 없다.)
- 프로세스가 메모리를 얼마나 많이 사용하고 있는지에 따라 프로세스의 최종 OOM 점수(oom_score) 가 갱신된다.
- OOM Killer는 이 점수를 기준으로 최종적으로 종료할 프로세스를 선정한다.

# QoS 클래스의 종류 - (1) Guaranteed 클래스

- QoS 클래스에는 `BestEffort`, `Burstable`, `Guaranteed` 총 3가지 종류가 있다.
- QoS 클래스는 따로 설정하지 않아도 자동으로 설정된다.
- `Guaranteed` 클래스는 파드의 컨테이너에 설정된 **Limits**와 **Requests** 값이 완전히 동일할 때 부여되는 클래스이다.

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: resource-limit-pod
  labels:
    name: resource-limit-pod
spec:
  containers:
  - name: nginx
    image: nginx:latest
    resources:
      limits:
        memory: "256Mi"
        cpu: "1000m"
```

- Requests 없이 Limits만 설정해도 `Guaranteed` 클래스로 분류된다.
    - Requests의 값 또한 Limits로 동일하게 설정된다.
- `Guaranteed` 클래스의 파드 내부에서 실행되는 프로세스들은 모두 기본 OOM 점수 (oom_score)가 -997로 설정된다.
    - 시스템 컨포넌트가 요구하지 않은 한 `Guaranteed` 의 파드나 프로세스가 강제로 종료될 일은 없다.

> 파드 내에 컨테이너가 여러 개 존재한다면 모든 컨테이너의 Requests와 Limits의 값이 완전히 같아야만 파드가 `Guaranteed` 클래스로 분류된다.
>

# QoS 클래스의 종류 - (2) BestEffort 클래스

- `BestEffort`는 Request와 Limits를 아예 설정하지 않은 파드의 설정되는 클래스이다.

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: nginx-besteffort-pod
spec:
  containers:
  - name: nginx-besteffort-pod
    image: nginx:latest
```

# QoS 클래스의 종류 - (3) Burstable 클래스

- `Burstable` 클래스는 Requests와 Limits가 설정돼 있지만, Limits의 값이 Requests보다 큰 파드를 의미한다.
- `Burstable` 클래스의 파드는 Requests에 지정된 자원만큼 사용을 보장받을 수 있지만 상황에 따라서는 Limits까지 자원을 사용할 수 있다.
- `Burstable` 클래스의 파드는 주어진 Requests 내에서 자원을 사용하면 문제가 없지만, Requests를 넘어 Limits 범위 내에서 자원을 사용하려고 시도한다면 다른 파드와 자원 경합이 발생할 수도 있다.
- 기본적으로 파드의 우선순위는 `Guaranteed` > `Burstable` > `BestEffort` 순이다.

# ResourceQuota로 자원 사용량 제한

`ResourceQuota`는 특정 네임스페이스에서 사용할 수 있는 자원 사용량의 합을 제한할 수 있는 쿠버네티스 오브젝트이다.

1. 네임스페이스에서 할당할 수 있는 자원(CPU, 메모리, 퍼시스턴스 볼륨 클레임의 크기, 컨테이너 내부의 임시 스터리지)의 총합을 제한할 수 있다.
2. 네임스페이스에서 생성할 수 있는 리소스(서비스, 디플로이먼트 등)의 개수를 제한할 수 있다.

> `ResourceQuota` 는 네임스페이스에 종속되는 오브젝트이기 때문에 네임스페이스 별로 `ResourceQuota` 리소스를 생성해야 한다. 기본적으로 어떠한 `ResourceQuota` 도 생성되어 있지 않다. (default X)
>

```yaml
apiVersion: v1
kind: ResourceQuota
metadata:
  name: resource-quota-example
  namespace: default
spec:
  hard:
    requests.cpu: "1000m"
    requests.memory: "500Mi"
    limits.cpu: "1500m"
    limits.memory: "1000Mi"
```

- `ResourceQuota` 를 생성하기 이전에 존재하고 있던 파드들이 이미 자원을 한계치보다 많이 사용하고 있다고 해서 기존의 파드가 종료되지 않는다.

# ResourceQuota로 리소스 개수 제한하기

1. 디플로이먼트, 파드, 서비스, 시크릿, 컨피그맵, 퍼시스턴스 볼륨 클레임 등의 개수
2. NodePort 타입의 서비스 개수, LoadBalancer 타입의 서비스 개수
3. QoS 클래스 중에서 BestEffort 클래스에 속하는 파드의 개수

파드나 서비스의 최대 개수를 제한하려면 YAML 파일에 `count/pod` 와 같은 형식으로 정의한다.

```yaml
apiVersion: v1
kind: ResourceQuota
metadata:
  name: resource-quota-example
  namespace: default
spec:
  hard:
    requests.cpu: "1000m"
    requests.memory: "500Mi"
    limits.cpu: "1500m"
    limits.memory: "1000Mi"
    count/pods: 3
    count/services: 5
```

리소스의 개수를 제한할 때 정의되는 쿠버네티스 오브젝트 이름은 count/<오브젝트 이름>.<API 그룹 이름>이다.

# ResourceQuota로 BestEffort 클래스의 파드 개수 제한하기

`ResourceQuota` 를 사용하면 Requests와 Limits가 모두 설정돼 있지 않아서 노드의 자원을 제한 없이 사용할 수 있는 파드, 즉 `BestEffort` 클래스의 파드 개수를 제한할 수 있다.

```yaml
apiVersion: v1
kind: ResourceQuota
metadata:
  name: besteffort-quota
  namespace: default
spec:
  hard:
    count/pods: 1
  scopes: 
    - BestEffort # BestEffort, NotBestEffort, Terminating, NotTerminating 파드의 상태 값을 정의
```

- NotBestEffort: BestEffort 클래스가 아닌 다른 QoS 클래스를 의미
- Terminating: 파드의 종료 시간(activeDeadlineSeconds)이 명시적으로 설정된 경우를 의미
- NotTerminating: 기본적으로 생성되는 오브젝트

> `ResourceQuota` 에 limits.cpu 나 limits.memory 등을 이용해 네임스페이스에서 사용 가능한 자원의 합을 설정했다면 파드를 생성할 때 반드시 해당 항목을 함께 정의해줘야 한다.
>

# LimitRange로 자원 사용량 제한

`LimitRange` 는 특정 네임스페이스에서 할당되는 자원의 범위 또는 기본값을 지정할 수 있는 쿠버네티스 오브젝트이다.

[LimitRange의 용도]

- 파드의 컨테이너에 CPU나 메모리 할당량이 설정돼 있지 않은 경우, 컨테이너에 자동으로 기본 Requests 또는 Limits 값을 설정할 수 있다.
- 파드 또는 컨테이너의 CPU, 메모리, 퍼시스턴스 볼륨 클레임 스토리지 크기의 최솟값/최댓값을 설정할 수 있다.

```yaml
apiVersion: v1
kind: LimitRange
metadata:
  name: mem-limit-range
spec:
  limits:
  - default:                # 1. 자동으로 설정될 기본 Limit 값
      memory: 256Mi
      cpu: 200m
    defaultRequest:        # 2. 자동으로 설정될 기본 Request 값
      memory: 128Mi
      cpu: 100m
    max:                   # 3. 자원 할당량의 최대값
      memory: 1Gi
      cpu: 1000m
    min:                   # 4. 자원 할당량의 최소값
      memory: 16Mi
      cpu: 50m
    type: Container        # 5. 각 컨테이너에 대해서 적용
```

`LimitRange`에서 `maxLimitRequestRatio` 항목을 사용하면 파드의 컨테이너에서 오버커밋되는 자원에 대한 비율을 제한할 수도 있다.

```yaml
apiVersion: v1
kind: LimitRange
metadata:
  name: limitrange-ratio
spec:
  limits:
  - maxLimitRequestRatio:
      memory: 1.5
      cpu: 1
    type: Container
```

위 예시에서는 `maxLimitRequestRatio` 의 값을 1.5로 설정했으며, 이는 새롭게 생성되는 파드의 Limits, Requests의 비율은 1.5보다 반드시 작아야 한다는 의미이다.

만약 파드의 단위로 자원 사용량의 범위를 제한하고 싶다면 아래의 YAML 파일처럼 정의하면 된다.

```yaml
apiVersion: v1
kind: LimitRange
metadata:
  name: pod-limit-range
spec:
  limits:
  - max:                   
      memory: 1Gi
    min:                   
      memory: 200Mi
    type: Pod  
```

# ResourceQuota, LimitRange의 원리: Admission Controller

- 사용자가 `kubectl` 등을 통해 쿠버네티스 API 서버에 요청을 보낼 때, 인증과 인가 외에도 어드미션 컨트롤러라는 단계가 존재한다.
- 어드미션 컨트롤러는 사용자의 API 요청이 적절한지 **검증**하고, 필요에 따라 API 요청을 **변형**하는 단계이다.
    - 서비스 어카운트(ServiceAccount)가 어드미션 컨트롤러의 한 종류이다.
    - 검증(Validating) 단계, 변형(Mutating) 단계가 있다.

> 기본적인 어드미션 컨트롤러는 대부분 기본적으로 활성화돼 있다.
>
